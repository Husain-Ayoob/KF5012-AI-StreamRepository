{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Once we have analysed the data, and decide it is suitable for machine learning, we then need to prcoess the data to prepare it for input to a machine learning algorithm. In this notebook we will cover some basics of pre-processing data for machine learning. Specifically, we will look at (1) Formatting the data correctly, and (2) Normalising the data.\n",
    "\n",
    "First, let us install the required packages and import the diabetes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv('Data/diabetes.tsv', sep='\\t', header=0)\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating data for (supervised) machine learning\n",
    "Supervised machine learning algorithms requires the data to be formatted a particular way. Specificially, the data needs to consist of an array of target values, often denoted $y$, and an array of attribute values, often denoted $X$.\n",
    "\n",
    "Let's look at how we would map the dibetes DataFrame to this format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us create an array of targets, $y$, by extracting the **Y** column from the diabetes DataFrame, and print the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_diabetes['Y']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create the array/DataFrame of attributes, denoted $X$, by dropping the target variable from diabetes DataFrame, and print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_diabetes.drop('Y', axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us compare the shapes of $y$ and $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that $X$ consists of $442$ samples of $10$ attributes. We also see that $y$ consists of $442$ samples, it is *one dimensional* (as opposed to two dimensional) array so have zero values in the second dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising data for (supervised) machine learning\n",
    "*Data normalisation* is often required for machine learning algorithms to perform well. Essentially, this ammounts to trying to make the data better suit the assumptions on which the algorithm was developed. Here we will explore transforming the attributes data to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us use the `agg` method to calculate the *mean* and *standard deviation* of the columns of $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.agg({'mean','std'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the data is easy in Pandas, we simply subtract the mean and divide by the standard deviation. Let's do that and then calculate the *mean* and *standard deviation* of the columns of $X$ once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(X-X.mean())/X.std()\n",
    "X.agg({'mean','std'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the standard deviation (std) is equal to $1$ (why does this mean the variance is also equal to $1$?). We also see that the mean is very close to zero (1.0e-17 is a very small number). This is close enough for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target array $y$ and the attributes array $X$ are now ready to be inputed into a machine learning algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
